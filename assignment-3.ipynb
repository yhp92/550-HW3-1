{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3\n",
    "\n",
    "**Due date: Monday 10/18, end of day**\n",
    "\n",
    "This assignment will contain two parts:\n",
    "\n",
    "1. Exploring evictions and code violations in Philadelphia\n",
    "2. Comparing the NDVI in Philadelphia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Exploring Evictions and Code Violations in Philadelphia\n",
    "\n",
    "In this assignment, we'll explore spatial trends evictions in Philadelphia using data from the [Eviction Lab](https://evictionlab.org/) and building code violations using data from [OpenDataPhilly](https://www.opendataphilly.org/).\n",
    "\n",
    "We'll be exploring the idea that evictions can occur as retaliation against renters for reporting code violations. Spatial correlations between evictions and code violations from the City's Licenses and Inspections department can offer some insight into this question. \n",
    "\n",
    "**A couple of interesting background readings:**\n",
    "- [HuffPost article](https://www.huffingtonpost.com/entry/cities-are-starting-to-pay-attention-to-the-eviction-crisis-thats-devastated-poor-tenants_us_5b1a7b21e4b0bbb7a0dbd59e)\n",
    "- [PlanPhilly article](http://planphilly.com/articles/2018/04/12/philly-landlords-evict-more-people-than-owners-in-other-large-cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Explore Eviction Lab Data\n",
    "\n",
    "The Eviction Lab built the first national database for evictions. If you aren't familiar with the project, you can explore their website: https://evictionlab.org/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Read data using `geopandas`\n",
    "\n",
    "The first step is to read the eviction data by census tract using `geopandas`. The data for all of Pennsylvania by census tract is available in the `data/` folder in a GeoJSON format.\n",
    "\n",
    "Load the data file \"PA-tracts.geojson\" using `geopandas`\n",
    "\n",
    "**Note:** If you'd like to see all columns in the data frame, you can increase the max number of columns using pandas display options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xd5 in position 65: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xd5 in position 65: invalid continuation byte"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'fiona._env.log_error'\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Miniconda3\\envs\\musa-550-fall-2021\\lib\\site-packages\\fiona\\env.py\", line 283, in defenv\n",
      "    local._env.start()\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xd5 in position 65: invalid continuation byte\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xd5 in position 65: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xd5 in position 65: invalid continuation byte"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'fiona._env.log_error'\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Miniconda3\\envs\\musa-550-fall-2021\\lib\\site-packages\\fiona\\env.py\", line 283, in defenv\n",
      "    local._env.start()\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xd5 in position 65: invalid continuation byte\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xd5 in position 70: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xd5 in position 70: invalid continuation byte"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'fiona._env.log_error'\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Miniconda3\\envs\\musa-550-fall-2021\\lib\\site-packages\\fiona\\env.py\", line 283, in defenv\n",
      "    local._env.start()\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xd5 in position 70: invalid continuation byte\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xd5 in position 70: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xd5 in position 70: invalid continuation byte"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'fiona._env.log_error'\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Miniconda3\\envs\\musa-550-fall-2021\\lib\\site-packages\\fiona\\env.py\", line 283, in defenv\n",
      "    local._env.start()\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xd5 in position 70: invalid continuation byte\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xd5 in position 61: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xd5 in position 61: invalid continuation byte"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'fiona._env.log_error'\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Miniconda3\\envs\\musa-550-fall-2021\\lib\\site-packages\\fiona\\env.py\", line 283, in defenv\n",
      "    local._env.start()\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xd5 in position 61: invalid continuation byte\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xd5 in position 61: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xd5 in position 61: invalid continuation byte"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'fiona._env.log_error'\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Miniconda3\\envs\\musa-550-fall-2021\\lib\\site-packages\\fiona\\env.py\", line 283, in defenv\n",
      "    local._env.start()\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xd5 in position 61: invalid continuation byte\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xd5 in position 65: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xd5 in position 65: invalid continuation byte"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'fiona._env.log_error'\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Miniconda3\\envs\\musa-550-fall-2021\\lib\\site-packages\\fiona\\env.py\", line 283, in defenv\n",
      "    local._env.start()\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xd5 in position 65: invalid continuation byte\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xd5 in position 65: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xd5 in position 65: invalid continuation byte"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'fiona._env.log_error'\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Miniconda3\\envs\\musa-550-fall-2021\\lib\\site-packages\\fiona\\env.py\", line 283, in defenv\n",
      "    local._env.start()\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xd5 in position 65: invalid continuation byte\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xd5 in position 70: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xd5 in position 70: invalid continuation byte"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'fiona._env.log_error'\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Miniconda3\\envs\\musa-550-fall-2021\\lib\\site-packages\\fiona\\env.py\", line 283, in defenv\n",
      "    local._env.start()\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xd5 in position 70: invalid continuation byte\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xd5 in position 70: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xd5 in position 70: invalid continuation byte"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'fiona._env.log_error'\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Miniconda3\\envs\\musa-550-fall-2021\\lib\\site-packages\\fiona\\env.py\", line 283, in defenv\n",
      "    local._env.start()\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xd5 in position 70: invalid continuation byte\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xd5 in position 61: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xd5 in position 61: invalid continuation byte"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'fiona._env.log_error'\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Miniconda3\\envs\\musa-550-fall-2021\\lib\\site-packages\\fiona\\env.py\", line 283, in defenv\n",
      "    local._env.start()\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xd5 in position 61: invalid continuation byte\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xd5 in position 61: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xd5 in position 61: invalid continuation byte"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'fiona._env.log_error'\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Miniconda3\\envs\\musa-550-fall-2021\\lib\\site-packages\\fiona\\env.py\", line 283, in defenv\n",
      "    local._env.start()\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xd5 in position 61: invalid continuation byte\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracts = gpd.read_file(\"E:/UPenn Work Files/MUSA_550/assignment-3-main/data/PA-tracts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Explore and trim the data \n",
    "\n",
    "We will need to trim data to Philadelphia only. Take a look at the data dictionary for the descriptions of the various columns in top-level repository folder: `eviction_lab_data_dictionary.txt`\n",
    "\n",
    "**Note:** the column names are shortened — see the end of the above file for the abbreviations. The numbers at the end of the columns indicate the years. For example, `e-16` is the number of evictions in 2016. \n",
    "\n",
    "Take a look at the individual columns and trim to census tracts in Philadelphia. (Hint: Philadelphia is both a city and a county)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 Transform from wide to tidy format\n",
    "\n",
    "For this assignment, we are interested in the number of evictions by census tract for various years. Right now, each year has it's own column, so it will be easiest to transform to a tidy format. \n",
    "\n",
    "Use the `pd.melt()` function to transform the eviction data into tidy format, using the number of evictions from **2003 to 2016**.\n",
    "\n",
    "The tidy data frame should have four columns: `GEOID`, `geometry`, a column holding the number of evictions, and a column telling you what the name of the original column was for that value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hints:**\n",
    "- You'll want to specify the `GEOID` and `geometry` columns as the `id_vars`. This will keep track of the census tract information. \n",
    "- You should specify the names of the columns holding the number of evictions as the `value_vars`.\n",
    "- You can generate a list of this column names using [Python's string formatting]:(https://docs.python.org/3.7/library/string.html#format-examples)\n",
    "    ```python\n",
    "    value_vars = ['e-{:02d}'.format(x) for x in range(3, 17)]\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.4 Plot the total number of evictions per year from 2003 to 2016\n",
    "\n",
    "Use `hvplot` to plot the total number of evictions from 2003 to 2016. You will first need to perform a group by operation and sum up the total number of evictions for all census tracts, and then use `hvplot()` to make your plot.\n",
    "\n",
    "You can use any type of `hvplot` chart you'd like to show the trend in number of evictions over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.5 The number of evictions across Philadelphia\n",
    "\n",
    "Our tidy data frame is still a GeoDataFrame with a geometry column, so we can visualize the number of evictions for all census tracts. \n",
    "\n",
    "Use `hvplot()` to generate a choropleth showing the number of evictions for a specified year, with a widget dropdown to select a given year (or variable name, e.g., `e-16`, `e-15`, etc). \n",
    "\n",
    "**Hints** \n",
    "- You'll need to use the `groupby` keyword to tell `hvplot` to make a series of maps, with a widget to select between them.\n",
    "- You will need to specify `dynamic=False` as a keyword argument to the `hvplot()` function. \n",
    "- Be sure to specify a `width` and `height` that makes your output map (roughly) square to limit distortions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Code Violations in Philadelphia\n",
    "\n",
    "Next, we'll explore data for code violations from the Licenses and Inspections Department of Philadelphia to look for potential correlations with the number of evictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Load data from 2012 to 2016\n",
    "\n",
    "L+I violation data for years including 2012 through 2016 (inclusive) is provided in a CSV format in the \"data/\" folder. \n",
    "\n",
    "Load the data using pandas and convert to a GeoDataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Trim to specific violation types\n",
    "\n",
    "There are many different types of code violations (running the `nunique()` function on the `violationdescription` column will extract all of the unique ones). More information on different types of violations can be found [on the City's website](https://www.phila.gov/li/codesandregulations/Pages/codes.aspx).\n",
    "\n",
    "Below, I've selected 15 types of violations that deal with property maintenance and licensing issues. We'll focus on these violations. The goal is to see if these kinds of violations are correlated spatially with the number of evictions in a given area. \n",
    "\n",
    "Use the list of violations given to trim your data set to only include these types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violation_types = [\n",
    "    \"INT-PLMBG MAINT FIXTURES-RES\",\n",
    "    \"INT S-CEILING REPAIR/MAINT SAN\",\n",
    "    \"PLUMBING SYSTEMS-GENERAL\",\n",
    "    \"CO DETECTOR NEEDED\",\n",
    "    \"INTERIOR SURFACES\",\n",
    "    \"EXT S-ROOF REPAIR\",\n",
    "    \"ELEC-RECEPTABLE DEFECTIVE-RES\",\n",
    "    \"INT S-FLOOR REPAIR\",\n",
    "    \"DRAINAGE-MAIN DRAIN REPAIR-RES\",\n",
    "    \"DRAINAGE-DOWNSPOUT REPR/REPLC\",\n",
    "    \"LIGHT FIXTURE DEFECTIVE-RES\",\n",
    "    \"LICENSE-RES SFD/2FD\",\n",
    "    \"ELECTRICAL -HAZARD\",\n",
    "    \"VACANT PROPERTIES-GENERAL\",\n",
    "    \"INT-PLMBG FIXTURES-RES\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 Make a hex bin map\n",
    "\n",
    "The code violation data is **point data**. We can get a quick look at the geographic distribution using `matplotlib` and the `hexbin()` function. Make a hex bin map of the code violations and overlay the census tract outlines. \n",
    "\n",
    "**Hints**:\n",
    "- The eviction data from part 1 was by census tract, so the census tract geometries are available as part of that GeoDataFrame. You can use it to overlay the census tracts on your hex bin map.\n",
    "- Make sure you convert your GeoDataFrame to a CRS that's better for visualization than plain old 4326."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.4 Spatially join data sets\n",
    "\n",
    "To do a census tract comparison to our eviction data, we need to find which census tract each of the code violations falls into. Use the `geopandas.sjoin()` function to do just that. \n",
    "\n",
    "\n",
    "**Hints**\n",
    "- You can re-use your eviction data frame, but you will only need the `geometry` column (specifying census tract polygons) and the `GEOID` column (specifying the name of each census tract).\n",
    "- Make sure both data frames have the same CRS before joining them together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.5 Calculate the number of violations by type per census tract\n",
    "\n",
    "Next, we'll want to find the number of violations (for each kind) per census tract. You should group the data frame by violation type and census tract name.\n",
    "\n",
    "The result of this step should be a data frame with three columns: `violationdescription`, `GEOID`, and `N`, where `N` is the number of violations of that kind in the specified census tract.\n",
    "\n",
    "**Optional: to make prettier plots**\n",
    "\n",
    "Some census tracts won't have any violations, and they won't be included when we do the above calculation. However, there is a trick to set the values for those census tracts to be zero. After you calculate the sizes of each violation/census tract group, you can run: \n",
    "\n",
    "```python\n",
    "N = N.unstack(fill_value=0).stack().reset_index(name='N')\n",
    "```\n",
    "where `N` gives the total size of each of the groups, specified by violation type and census tract name.\n",
    "\n",
    "See [this StackOverflow post](https://stackoverflow.com/questions/42854801/including-missing-combinations-of-values-in-a-pandas-groupby-aggregation) for more details.\n",
    "\n",
    "This part is **optional**, but will make the resulting maps a bit prettier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.6 Merge with census tracts geometries\n",
    "\n",
    "We now have the number of violations of different types per census tract specified as a regular DataFrame. You can now merge it with the census tract geometries (from your eviction data GeoDataFrame) to create a GeoDataFrame. \n",
    "\n",
    "**Hints**\n",
    "- Use `pandas.merge()` and specify the `on` keyword to be the column holding census tract names. \n",
    "- Make sure the result of the merge operation is a GeoDataFrame — you will want the GeoDataFrame holding census tract geometries to be the first argument of the `pandas.merge()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.7 Interactive choropleths for each violation type\n",
    "\n",
    "Now, we can use `hvplot()` to create an interactive choropleth for each violation type and add a widget to specify different violation types. \n",
    "\n",
    "**Hints** \n",
    "- You'll need to use the `groupby` keyword to tell `hvplot` to make a series of maps, with a widget to select different violation types.\n",
    "- You will need to specify `dynamic=False` as a keyword argument to the `hvplot()` function. \n",
    "- Be sure to specify a `width` and `height` that makes your output map (roughly) square to limit distortions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. A side-by-side comparison\n",
    "\n",
    "From the interactive maps of evictions and violations, you should notice a lot of spatial overlap. \n",
    "\n",
    "As a final step, we'll make a side-by-side comparison to better show the spatial correlations. This will involve a few steps: \n",
    "\n",
    "1. Trim the data frame plotted in section 1.1.5 to only include evictions from 2016. \n",
    "2. Trim the data frame plotted in section 1.2.7 to only include a single violation type (pick whichever one you want!).\n",
    "3. Use `hvplot()` to make two interactive choropleth maps, one for the data from step 1. and one for the data in step 2.\n",
    "4. Show these two plots side by side (one row and 2 columns) using the syntax for combining charts.\n",
    "\n",
    "**Note:** since we selected a single year and violation type, you won't need to use the `groupby=` keyword here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Extra Credit\n",
    "\n",
    "Identify the 20 most common types of violations within the time period of 2012 to 2016 and create a set of interactive choropleths similar to what was done in section 1.2.7. \n",
    "\n",
    "Use this set of maps to identify 3 types of violations that don't seem to have much spatial overlap with the number of evictions in the City."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Exploring the NDVI in Philadelphia\n",
    "\n",
    "In this part, we'll explore the NDVI in Philadelphia a bit more. This part will include two parts:\n",
    "\n",
    "1. We'll compare the median NDVI within the city limits and the immediate suburbs\n",
    "1. We'll calculate the  NDVI around street trees in the city."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Comparing the NDVI in the city and the suburbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Load Landsat data for Philadelphia\n",
    "\n",
    "Use rasterio to load the landsat data for Philadelphia (available in the \"data/\" folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Separating the city from the suburbs\n",
    "\n",
    "Create two polygon objects, one for the city limits and one for the suburbs. To calculate the suburbs polygon, we will take everything outside the city limits but still within the bounding box. \n",
    "\n",
    "* The city limits are available in the \"data/\" folder.\n",
    "* To calculate the suburbs polygon, the \"envelope\" attribute of the city limits geometry will be useful.\n",
    "* You can use geopandas' [geometric manipulation](http://geopandas.org/geometric_manipulations.html#examples-of-geometric-manipulations) functionality to calculate the suburbs polygon from the city limits polygon and the envelope polygon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 Mask and calculate the NDVI for the city and the suburbs\n",
    "\n",
    "Using the two polygons from the last section, use rasterio's mask functionality to create two masked arrays from the landsat data, one for the city and one for the suburbs. \n",
    "\n",
    "For each masked array, calculate the NDVI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.4 Calculate the median NDVI within the city and within the suburbs\n",
    "\n",
    "* Calculate the median value from your NDVI arrays for the city and suburbs\n",
    "* Numpy's `nanmedian` function will be useful for ignoring NaN elements\n",
    "* Print out the median values. Which has a higher NDVI: the city or suburbs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Calculating the NDVI for Philadelphia's street treets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Load the street tree data\n",
    "\n",
    "The data is available in the \"data/\" folder. It has been downloaded from [OpenDataPhilly](https://www.opendataphilly.org/dataset/ppr-tree-canopy). It contains the locations of abot 2,500 street trees in Philadelphia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Calculate the NDVI values at the locations of the street trees\n",
    "\n",
    "* Use the rasterstats package to calculate the NDVI values at the locations of the street trees.\n",
    "* Since these are point geometries, you can calculate either the median or the mean statistic (only one pixel will contain each point)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Plotting the results\n",
    "\n",
    "Make two plots of the results:\n",
    "\n",
    "1. A histogram of the NDVI values, using matplotlib's `hist` function. Include a vertical line that marks the NDVI = 0 threshold\n",
    "1. A plot of the street tree points, colored by the NDVI value, using geopandas' `plot` function. Include the city limits boundary on your plot.\n",
    "\n",
    "The figures should be clear and well-styled, with for example, labels for axes, legends, and clear color choices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
